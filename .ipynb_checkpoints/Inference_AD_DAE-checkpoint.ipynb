{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b420c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from metrics_cond import *\n",
    "import slice_view\n",
    "import torch.nn.functional as F\n",
    "import nibabel as nib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f38f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize tensors\n",
    "def normalize_tensor(tensor, min_range, max_range):\n",
    "    min_vals = torch.min(tensor, dim=2).values.min(dim=2).values\n",
    "    max_vals = torch.max(tensor, dim=2).values.max(dim=2).values\n",
    "    normalized_tensor = (tensor - min_vals.unsqueeze(2).unsqueeze(3)) / (max_vals.unsqueeze(2).unsqueeze(3) - min_vals.unsqueeze(2).unsqueeze(3))\n",
    "    normalized_tensor = normalized_tensor * (max_range - min_range) + min_range\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fff4cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 129.18 M\n"
     ]
    }
   ],
   "source": [
    "# Model call\n",
    "import AD_DAE_model_call as model_call\n",
    "model = model_call.AD_DAE_model_call_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4d23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c2aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data_name ADNI\n",
      "['__image', '__baseline_image'] ['__label', '__baseline_label']\n",
      "in fuction ['__image', '__baseline_image', '__label', '__baseline_label']\n",
      "train data: 75350\n",
      "self.data_name ADNI\n",
      "['__image', '__baseline_image'] ['__label', '__baseline_label']\n",
      "in fuction ['__image', '__baseline_image', '__label', '__baseline_label']\n",
      "val data: 31100\n"
     ]
    }
   ],
   "source": [
    "# Retrieve model configuration from the model object\n",
    "conf = model.conf\n",
    "\n",
    "# Set device to CUDA for GPU acceleration\n",
    "device = 'cuda'\n",
    "\n",
    "# Create training dataset using configuration parameters\n",
    "# - Loads data from specified paths, including CSV and HDF5 files\n",
    "# - Includes ventricle mask for region-specific analysis (e.g., AD progression)\n",
    "model.train_data = model.conf.make_dataset(path=model.conf.data_config_path,\n",
    "                                               csv_path=model.conf.csv_path,\n",
    "                                               h5_save_path=model.conf.h5_save_path_train,\n",
    "                                               csv_file_name=model.conf.csv_file_name_train, \n",
    "                                               csv_mask_name=model.conf.csv_mask_name_train,\n",
    "                                               ventricle_mask_root_path=model.conf.ventricle_mask_root_path)\n",
    "\n",
    "# Print the number of training samples\n",
    "print('train data:', len(model.train_data))\n",
    "\n",
    "# Create validation dataset using configuration parameters\n",
    "# - Similar to training dataset but uses test-specific paths\n",
    "model.val_data = model.conf.make_dataset(path=model.conf.data_config_path,\n",
    "                                         csv_path=model.conf.csv_path_test,\n",
    "                                         h5_save_path=model.conf.h5_save_path_test,\n",
    "                                         csv_file_name=model.conf.csv_file_name_test, \n",
    "                                         csv_mask_name=model.conf.csv_mask_name_test,\n",
    "                                         ventricle_mask_root_path=model.conf.ventricle_mask_root_path)\n",
    "\n",
    "# Print the number of validation samples\n",
    "print('val data:', len(model.val_data))\n",
    "\n",
    "# Define batch sizes for training and evaluation\n",
    "batch_size = 50\n",
    "batch_size_eval = 50\n",
    "\n",
    "# Create DataLoader for training data\n",
    "# - shuffle=False: Maintains data order\n",
    "# - num_workers=1: Single worker for data loading\n",
    "# - pin_memory=True: Optimizes data transfer to GPU\n",
    "train_dataloader = DataLoader(model.train_data, shuffle=False, batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "\n",
    "# Create DataLoader for validation data\n",
    "# - Similar configuration to training DataLoader\n",
    "test_dataloader = DataLoader(model.val_data, shuffle=False, batch_size=batch_size_eval, num_workers=1, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62242dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c8d5c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                          | 0/1507 [01:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: ADNI_033_S_1285_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20090317135732405_S63539_I139246.nii\n",
      "Baseline Age:  81.7\n",
      "Follow-up Age:  82.2\n",
      "Cognitive State:  AD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a lambda function to convert a list of ages to a stacked tensor of floats\n",
    "str_float_tensor = lambda age_list: torch.stack([torch.tensor(float(age)) for age in age_list])\n",
    "\n",
    "# Initialize list to store results (commented out in original code)\n",
    "# save_results = []\n",
    "\n",
    "# Iterate over training DataLoader with progress bar\n",
    "for batch in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "    # Flag to start generation from noise (True) or encoded latent (False)\n",
    "    start_from_noise = True  # True\n",
    "\n",
    "    # Set mode to 'train' for accessing training-specific batch keys\n",
    "    mode = 'train'\n",
    "\n",
    "    # Disable gradient computation for evaluation-like inference\n",
    "    with torch.no_grad():\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        # Move model to GPU\n",
    "        model.cuda()\n",
    "        # Set latent shift predictor to evaluation mode\n",
    "        model.model.eval()\n",
    "        # Move latent shift predictor to GPU\n",
    "        model.model.cuda()\n",
    "\n",
    "    # Initialize dictionary to store batch results\n",
    "    save_dict_ = {}\n",
    "\n",
    "    # Extract ventricle mask from batch for region-specific processing\n",
    "    ventricle_mask_batch = batch['ventricle_mask']\n",
    "\n",
    "    # Normalize training images to [0, 1] range\n",
    "    x_start = normalize_tensor(batch['_'+mode+'_image'], 0, 1)\n",
    "\n",
    "    # Normalize baseline images to [0, 1] range\n",
    "    x_start_baseline = normalize_tensor(batch['_'+mode+'_baseline_image'], 0, 1)\n",
    "\n",
    "    # Move baseline images to GPU\n",
    "    x_start_baseline = x_start_baseline.cuda()\n",
    "\n",
    "    # Extract indices from batch\n",
    "    idxs = batch['idx']\n",
    "\n",
    "    #################################\n",
    "    # Calculate age difference between follow-up and baseline ages\n",
    "    age_diff = model.str_list_tensor(batch['Age']) - model.str_list_tensor(batch['baseline Age'])\n",
    "    # Ensure age_diff matches the image tensor's data type\n",
    "    age_diff = age_diff.to(batch['_'+mode+'_image'].dtype)\n",
    "\n",
    "    # Initialize condition vector (12 dimensions) for progression attributes\n",
    "    cond_vector = torch.zeros(batch['_'+mode+'_image'].shape[0], 12)\n",
    "\n",
    "    # Get condition vector, shifts, and shifted condition vector from batch\n",
    "    # - Incorporates cognitive status (v_d) and age gap (v_a)\n",
    "    cond_vector, shifts, cond_vector_shift = model.get_data_elements(batch, age_diff, cond_vector)\n",
    "\n",
    "    # Assign shifted condition vector as health state\n",
    "    health_state = cond_vector_shift\n",
    "\n",
    "    # Move shifted condition vector to same dtype and device as age_diff\n",
    "    cond_vector_shift = cond_vector_shift.to(age_diff.dtype).to(age_diff.device)\n",
    "\n",
    "    # Move condition vector to same dtype and device\n",
    "    cond_vector = cond_vector.to(age_diff.dtype).to(age_diff.device)\n",
    "\n",
    "    # Move normalized training images to GPU\n",
    "    x_start = x_start.cuda()\n",
    "\n",
    "    # Generate random noise for diffusion process (same shape as x_start)\n",
    "    noise = torch.randn(x_start.shape[0], 1, x_start.shape[2], x_start.shape[3], device=x_start.device)\n",
    "\n",
    "    # Set ventricle mask for sampler (used in rendering)\n",
    "    model.sampler.ventricle_mask_batch = ventricle_mask_batch\n",
    "\n",
    "    # Set age shift for sampler and move to correct dtype/device\n",
    "    model.sampler.age_shift = shifts.to(batch['_'+mode+'_image'].dtype).to(batch['_'+mode+'_image'].device)\n",
    "\n",
    "    # Set weight for condition shift in sampler\n",
    "    model.sampler.cond_shift_weight = 1\n",
    "\n",
    "    # Get latent shift predictor module\n",
    "    shift_predictor = model.model.latent_shift_predictor\n",
    "\n",
    "    # Set predictor to evaluation mode\n",
    "    shift_predictor.eval()\n",
    "\n",
    "    # Predict latent shift based on shifted condition vector\n",
    "    shift_new = shift_predictor.forward(cond_vector_shift.cuda())\n",
    "\n",
    "    # Encode baseline image to latent representation\n",
    "    cond_baseline = model.encode(batch['_'+mode+'_baseline_image'].to(device))\n",
    "\n",
    "    # Encode baseline image stochastically with 200 diffusion steps\n",
    "    # - Uses baseline image, condition, and age/health attributes\n",
    "    xT = model.encode_stochastic(batch['_'+mode+'_baseline_image'].to(device), cond_baseline, T=200,\n",
    "                                x_start_baseline=x_start_baseline.cuda(), age_diff=age_diff.cuda(),\n",
    "                                health_state=health_state.cuda())\n",
    "\n",
    "    # Clone predicted shift for modification\n",
    "    shift_new_modf = shift_new.clone()\n",
    "\n",
    "    # Adjust shift for cases where age difference is zero\n",
    "    # - Copies last 50 dimensions to first 50 dimensions\n",
    "    for ind_, diff in enumerate(age_diff):\n",
    "        if diff == 0:\n",
    "            shift_new_modf[ind_][0:50] = shift_new_modf[ind_][450:500]\n",
    "\n",
    "    # Choose starting point: noise or encoded latent\n",
    "    if start_from_noise:\n",
    "        start_ = noise\n",
    "    else:\n",
    "        start_ = xT\n",
    "\n",
    "    # Render follow-up image\n",
    "    pred_followup_xT_shift_ = model.render(start_, {'cond': cond_baseline + (shift_new_modf)}, T=50,\n",
    "                                           mask_mult=False,\n",
    "                                           health_state=cond_vector_shift.to(device))\n",
    "\n",
    "    # Apply label mask to predicted follow-up image\n",
    "    pred_followup_xT_shift = pred_followup_xT_shift_ * batch['_'+mode+'_label'].to(torch.float32).cuda()\n",
    "\n",
    "    # Apply label mask to normalized training image\n",
    "    x_start_ = x_start * batch['_'+mode+'_label'].to(torch.float32).cuda()\n",
    "\n",
    "    # Apply label mask to normalized baseline image\n",
    "    x_start_baseline_ = x_start_baseline * batch['_'+mode+'_label'].to(torch.float32).cuda()\n",
    "\n",
    "    # Store results in a list (commented out in original code)\n",
    "    # save_results.append({\"pred_followup_xT_shift\":pred_followup_xT_shift,\\\n",
    "    #                      \"x_start_\":x_start_,\\\n",
    "    #                      \"x_start_baseline_\":x_start_baseline_})\n",
    "\n",
    "    # Convert baseline and follow-up ages to tensors\n",
    "    starting_age = torch.tensor(float(batch['baseline Age'][0]))\n",
    "    followup_age = torch.tensor(float(batch['Age'][0]))\n",
    "\n",
    "    # Print subject information for debugging\n",
    "    print('Subject:', batch['nii path'][0].split('/')[-1])\n",
    "    print(\"Baseline Age: \", batch['baseline Age'][0])\n",
    "    print('Follow-up Age: ', batch['Age'][0])\n",
    "    print('Cognitive State: ', batch['Health status'][0])\n",
    "\n",
    "    # Create dictionary to save results\n",
    "    save_dict = {'pred_followup_xT_shift': pred_followup_xT_shift,\n",
    "                 'x_start_': x_start_,\n",
    "                 'x_start_baseline_': x_start_baseline_,\n",
    "                 'baseline Age': batch['baseline Age'][0],\n",
    "                 'Age': batch['Age'][0],\n",
    "                 'Health status': batch['Health status'],\n",
    "                 'baseline nii path': batch['baseline nii path'][0],\n",
    "                 'nii path': batch['nii path'][0]\n",
    "                 }\n",
    "\n",
    "    # Generate unique ID for saving results\n",
    "    uniq_id = batch['Subject'][0]+'_'+str(round(followup_age.item(),2))+'_'+str(round(starting_age.item(),2))+'.pt'\n",
    "\n",
    "    # Define save path for results\n",
    "    AD_DAE_save_path = './save_results/'\n",
    "\n",
    "    # Create save directory if it doesn't exist\n",
    "    if not os.path.exists(AD_DAE_save_path):\n",
    "        os.mkdir(AD_DAE_save_path)\n",
    "\n",
    "    # Save results dictionary as a PyTorch file\n",
    "    torch.save(save_dict, AD_DAE_save_path+uniq_id)\n",
    "\n",
    "    # Exit loop after processing one batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0d6126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0e3efd381045de82164686942d6196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('x', 'y', 'z'), value='x'), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3D Loading of Ground-truth\n",
    "slc = slice_view.slicer((save_dict['x_start_'])[:,0,:,:].detach().cpu())\n",
    "slc.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eed8b00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edabe04be1fa4df79d7571bfeb9835fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('x', 'y', 'z'), value='x'), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3D Loading of Generated Images\n",
    "slc = slice_view.slicer((save_dict['pred_followup_xT_shift'])[:,0,:,:].detach().cpu())\n",
    "slc.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a98e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b32458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
